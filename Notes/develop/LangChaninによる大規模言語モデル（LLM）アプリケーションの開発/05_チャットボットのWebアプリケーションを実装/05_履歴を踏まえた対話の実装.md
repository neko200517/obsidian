## src/chatbot_engine.py

ConvesationChainに履歴を渡すことで今までの履歴を踏まえた答えを返す。

```python
from langchain.globals import set_verbose
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.memory import ChatMessageHistory
from langchain.schema import HumanMessage
from langchain.chains import ConversationChain

set_verbose(True)

def chat_with_history(message: str, history: ChatMessageHistory) -> str:
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)
    convesation = ConversationChain(llm=llm, memory=ConversationBufferMemory())

    messages = history.messages
    messages.append(HumanMessage(content=message))

    return convesation.predict(input=messages)
```

## src/gradio_ai_memory.py

chat_historyに今までの履歴がList形式で保存されているので、ChatMessageHistory形に変換してchat_with_history関数に渡す。

```python
import gradio as gr
from dotenv import load_dotenv
from chatbot_engine import chat_with_history
from langchain.memory import ChatMessageHistory

def ai_response(message, chat_history):
    history = ChatMessageHistory()
    for [user_message, ai_message] in chat_history:
       history.add_user_message(user_message)
       history.add_ai_message(ai_message)

    bot_message = chat_with_history(message, history)
    
    return bot_message

demo = gr.ChatInterface(ai_response)

if __name__ == "__main__":
  load_dotenv()
  demo.launch()
```